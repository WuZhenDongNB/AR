# AR
利用图片扫描技术和苹果自带SceneKit框架打造一个AR场景


扫描特定的图片,展示出一个真实的3D模型;

需要2步 1: 图片识别   2:利用苹果的SceneKit框架加载模型,


1:图片识别
1.1利用第三方AR开发包去实现。时至今日，AR技术有了一定的发展，可以利用第三方的framework开发包导入工程来实现。而且国内外都有。国外的就是高通的AR实现方案。在高通VR的官网https://developer.vuforia.com/上，我们可以下载支持ios开发的framework,并且高通提供了一些实例demo，有关识别后显示3D物体，video等的一些基础与高级识别结果。国内的有easyAR http://www.easyar.cn/，跟高通AR有类似的功能，两者的操作方法略有不同，高通需要把图片传到其网站上的，而easyAR是可以直接在工程上替换想要识别的图片的，所以说在设定识别图片的方便度上，easyAR要比高通AR做的好一些。而在示例demo上二者大同小异，不过高通做的比easyAR要好一些,本demo中利用的是easyAR,任何图片都必须先保存在本地中,本文实现了,拍照,从相册中,从网络获取图片并进行保存,然后扫描即可;

1.2:在 OpenGLView.mm 文件中的void HelloAR::render()可给出扫描图片的结果;




2.利用scenKit框架加载模型;

2.1为了模拟真实的AR场景,需要在扫描图片成功后加载一个相机的预览对象AVCaptureVideoPreviewLayer,在预览对象上加载模型;

2.1.1创建 SCNView ,这是基于Scenkit框架的一个视图,在这个视图上加载模型;

2.1.2,在加载玩SCNview视图后,即可显示3D模型,这时候3D模型是随手机移动的,为了让3d模型停留在原来的刚开始扫描的位置,这时候就要利用CMMotionManager,CMMotionManager可以理解为是CoreMotion Framework的中央管理器，也可以理解为运动服务。这些服务提供了获取加速机数据、旋转数据和磁力数据等。
在刚开始加载3d模型的时候,需要获取到手机的初始位置,然后手机移动的时候,让模型已偏移,就能够达到3d模型一直在刚开始位置的效果;


